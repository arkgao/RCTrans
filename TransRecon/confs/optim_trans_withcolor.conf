general {
    base_exp_dir = ./exp/CASE_NAME
    exp_name = optim_trans_withcolor
    recording = [
        ./,
    ]
}

reflection = False

optim_transparent{
    # coarse to fine
    init_sigma = 20
    coarse_level = 30000
    
    learning_rate = 1e-5
    learning_rate_alpha = 0.05

    end_iter = 300000
    igr_weight = 1.5
    mask_weight= 1.0
    color_weight = 1.0
    color_batch_size = 1024
    mask_batch_size = 256
    optim_obj_variance = False
    loss_type = l1

    optim_ior  = True
    init_ior = 1.60
    ior_lr = 1e-5
    
   
    report_freq = 1000
    save_freq  = 100000
    val_freq   = 5000
    val_mesh_freq = 20000

    
}

visualize{
    n_samples = 512
}

dataset {
    data_dir = ./data/CASE_NAME/
    render_cameras_name = cameras_sphere.npz
    object_cameras_name = object_sphere.npz
}

renderer{
    tracer{
        n_samples = 16
        n_importance = 16
        up_sample_steps = 1     # 1 for simple coarse-to-fine sampling
        perturb = 0
        ray_tracing_method = interpolate
    }

    scene_renderer{
        type = texture
        }

    trans_renderer {
        objIOR = 1.5
        airIOR = 1.0
        reflection_flag = False
    }
}

model {    

    nerf {
        D = 8,
        d_in = 4,
        d_in_view = 3,
        W = 256,
        multires = 10,
        multires_view = 4,
        output_ch = 4,
        skips=[4],
        use_viewdirs=True
    }

    sdf_network {
        d_out = 257
        d_in = 3
        d_hidden = 256
        n_layers = 8
        skip_in = [4]
        multires = 6
        bias = 0.5
        scale = 1.0
        geometric_init = True
        weight_norm = True
    }

    variance_network {
        init_val = 0.3
    }

    rendering_network {
        d_feature = 256
        mode = idr
        d_in = 9
        d_out = 3
        d_hidden = 256
        n_layers = 4
        weight_norm = True
        multires_view = 4
        squeeze_out = True
    }
}


